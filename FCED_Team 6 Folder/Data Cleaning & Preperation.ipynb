{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406abf59",
   "metadata": {},
   "source": [
    "# DATA CLEANING AND PREPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15f94593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('japandata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfaef152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:  0\n"
     ]
    }
   ],
   "source": [
    "# check for any duplicates + removing\n",
    "duplicate_rows = data.duplicated().sum()\n",
    "print(\"Number of duplicate rows: \", duplicate_rows)\n",
    "\n",
    "if duplicate_rows > 0:\n",
    "    data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e31dd",
   "metadata": {},
   "source": [
    "# Feature editing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5d37ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 'time' from string to datetime\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Feature Engineering (year used during one of the cleaning steps so we did this early)\n",
    "data['year'] = data['time'].dt.year\n",
    "data['month'] = data['time'].dt.month\n",
    "data['day'] = data['time'].dt.day\n",
    "data['mag_category'] = pd.cut(data['mag'], bins=[0, 4.9, 5.9, 6.9, 10], labels=[1, 2, 3, 4])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data['normalized_magnitude'] = scaler.fit_transform(data[['mag']])\n",
    "\n",
    "# season function to add as feature in new dataset\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 1\n",
    "    elif 6 <= month <= 8:\n",
    "        return 2\n",
    "    elif 9 <= month <= 11:\n",
    "        return 3\n",
    "    else:  # December to February\n",
    "        return 4\n",
    "\n",
    "data['season'] = data['month'].apply(get_season)\n",
    "\n",
    "\n",
    "# Dropping features we dont need\n",
    "data = data.drop(['magType', 'gap', 'dmin', 'rms', 'net', 'id', 'updated', 'place', 'type', 'status', 'locationSource', 'magSource'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d612a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c99b72fd",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fde4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                       0\n",
      "latitude                   0\n",
      "longitude                  0\n",
      "depth                      0\n",
      "mag                        0\n",
      "nst                        0\n",
      "horizontalError         6743\n",
      "depthError              2931\n",
      "magError                6460\n",
      "magNst                     0\n",
      "year                       0\n",
      "month                      0\n",
      "day                        0\n",
      "mag_category               0\n",
      "normalized_magnitude       0\n",
      "season                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dropping rows without mag (its an important feature + only hanful missing)\n",
    "data = data.dropna(subset=['mag'])\n",
    "\n",
    "# outlier detection for 'depth, magError, depthError, horizontalError'\n",
    "depth_q1 = data['depth'].quantile(0.25)\n",
    "depth_q3 = data['depth'].quantile(0.75)\n",
    "depth_iqr = depth_q3 - depth_q1\n",
    "depth_lower_bound = depth_q1 - 1.5 * depth_iqr\n",
    "depth_upper_bound = depth_q3 + 1.5 * depth_iqr\n",
    "data = data[\n",
    "    (data['depth'].isna()) | \n",
    "    ((data['depth'] >= depth_lower_bound) & (data['depth'] <= depth_upper_bound))\n",
    "]\n",
    "\n",
    "magError_q1 = data['magError'].quantile(0.25)\n",
    "magError_q3 = data['magError'].quantile(0.75)\n",
    "magError_iqr = magError_q3 - magError_q1\n",
    "magError_lower_bound = magError_q1 - 1.5 * magError_iqr\n",
    "magError_upper_bound = magError_q3 + 1.5 * magError_iqr\n",
    "data = data[\n",
    "    (data['magError'].isna()) | \n",
    "    ((data['magError'] >= magError_lower_bound) & (data['magError'] <= magError_upper_bound))\n",
    "]\n",
    "\n",
    "depthError_q1 = data['depthError'].quantile(0.25)\n",
    "depthError_q3 = data['depthError'].quantile(0.75)\n",
    "depthError_iqr = depthError_q3 - depthError_q1\n",
    "depthError_lower_bound = depthError_q1 - 1.5 * depthError_iqr\n",
    "depthError_upper_bound = depthError_q3 + 1.5 * depthError_iqr\n",
    "data = data[\n",
    "    (data['depthError'].isna()) | \n",
    "    ((data['depthError'] >= depthError_lower_bound) & (data['depthError'] <= depthError_upper_bound))\n",
    "]\n",
    "\n",
    "horizontalError_q1 = data['horizontalError'].quantile(0.25)\n",
    "horizontalError_q3 = data['horizontalError'].quantile(0.75)\n",
    "horizontalError_iqr = horizontalError_q3 - horizontalError_q1\n",
    "horizontalError_lower_bound = horizontalError_q1 - 1.5 * horizontalError_iqr\n",
    "horizontalError_upper_bound = horizontalError_q3 + 1.5 * horizontalError_iqr\n",
    "data = data[\n",
    "    (data['horizontalError'].isna()) | \n",
    "    ((data['horizontalError'] >= horizontalError_lower_bound) & (data['horizontalError'] <= horizontalError_upper_bound))\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# handling missing values\n",
    "# depth\n",
    "data['depth'] = data['depth'].fillna(data['depth'].median())\n",
    "\n",
    "\n",
    "# magNst\n",
    "data['time_group'] = data['year'].apply(lambda x: 'before_2011' if x <= 2010 else 'after_2011')\n",
    "medians = data.groupby('time_group')['magNst'].transform('median')\n",
    "data = data.drop('time_group', axis=1)\n",
    "data['magNst'] = data['magNst'].fillna(medians)\n",
    "\n",
    "# nst\n",
    "median_nst = data.loc[data['year'] <= 2013, 'nst'].median()\n",
    "data['nst'] = data['nst'].fillna(median_nst)\n",
    "\n",
    "# the Errors\n",
    "columns_to_fill = ['horizontalError', 'depthError', 'magError']\n",
    "data[columns_to_fill] = data[columns_to_fill].fillna(value=pd.NA)\n",
    "\n",
    "\n",
    "\n",
    "# final check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4144e6",
   "metadata": {},
   "source": [
    "## For error-related features, we're leaving them as NAN to indicate uncertainty. We also didnt want to fill it in as they were a big chunk of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121743e",
   "metadata": {},
   "source": [
    "# Data integrity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c7eec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (data['depth'] >= 0).all(), \"Depth contains negative values\"\n",
    "assert (data['mag'] >= 0).all(), \"Magnitude contains negative values\"\n",
    "assert (data['latitude'].between(-90, 90)).all(), \"Latitude out of bounds\"\n",
    "assert (data['longitude'].between(-180, 180)).all(), \"Longitude out of bounds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b491712",
   "metadata": {},
   "source": [
    "# Saving new data to different file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "390abb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_japandata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ef19a",
   "metadata": {},
   "source": [
    "# Checking final number of rows and colums to physically compare with the new cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2001a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 9607\n",
      "Number of cols: 16\n"
     ]
    }
   ],
   "source": [
    "num_rows = data.shape[0]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "num_cols = data.shape[1]\n",
    "print(\"Number of cols:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0fb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
